{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cover download method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/opiumozor/spotify-cover-downloader\n",
    "\n",
    "CLIENT_ID = \"\"\n",
    "CLIENT_SECRET = \"\"\n",
    "\n",
    "\n",
    "def get_access_token(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Get the access token from Spotify\n",
    "    \"\"\"\n",
    "    body_params = {'grant_type': \"client_credentials\"}\n",
    "    url = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    response = requests.post(url, data=body_params, auth=(client_id, client_secret))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['access_token']\n",
    "    else:\n",
    "        sys.exit(\"Failed to get access token. Is your client_id and client_secret correct?\")\n",
    "\n",
    "\n",
    "def get_api_url(url):\n",
    "    \"\"\"\n",
    "    Get the api url from the song link or the Spotify URI\n",
    "\n",
    "    Example:\n",
    "    - https://open.spotify.com/track/7H9sqtNVPp6eoxnJRMUmm4?si=jtQGu_1MQGOF-2WscCvbnA\n",
    "    - spotify:track:7H9sqtNVPp6eoxnJRMUmm4\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    type = None\n",
    "    spotify_id = None\n",
    "\n",
    "    if parsed_url.scheme == 'http' or parsed_url.scheme == 'https':\n",
    "        type = parsed_url.path.split('/')[1]\n",
    "        spotify_id = parsed_url.path.split('/')[2]\n",
    "    elif parsed_url.scheme == 'spotify':\n",
    "        type = parsed_url.path.split(':')[0]\n",
    "        spotify_id = parsed_url.path.split(':')[1]\n",
    "    else:\n",
    "        sys.exit(\"Failed to build api url.\")\n",
    "\n",
    "    return \"https://api.spotify.com/v1/%ss/%s\" % (type, spotify_id)  # add an 's' after the type\n",
    "\n",
    "\n",
    "def spotify_cover_downloader(url, client_id, client_secret, filename):\n",
    "    \"\"\"\n",
    "    Download an album cover from Spotify\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": \"Bearer %s\" % get_access_token(client_id, client_secret)}\n",
    "    url = get_api_url(url)\n",
    "\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "\n",
    "\n",
    "    cover_url = response['album']['images'][0]['url']\n",
    "    file_name = \"./covers/\" + filename + \".jpg\"\n",
    "\n",
    "    img_data = requests.get(cover_url).content\n",
    "    with open(file_name, 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "\n",
    "    print (\"Cover saved! (%s)\" % file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/un33k/python-slugify/blob/master/slugify/slugify.py\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from html.entities import name2codepoint\n",
    "try:\n",
    "    import text_unidecode as unidecode\n",
    "except ImportError:\n",
    "    import unidecode\n",
    "\n",
    "CHAR_ENTITY_PATTERN = re.compile(r'&(%s);' % '|'.join(name2codepoint))\n",
    "DECIMAL_PATTERN = re.compile(r'&#(\\d+);')\n",
    "HEX_PATTERN = re.compile(r'&#x([\\da-fA-F]+);')\n",
    "QUOTE_PATTERN = re.compile(r'[\\']+')\n",
    "DISALLOWED_CHARS_PATTERN = re.compile(r'[^-a-zA-Z0-9]+')\n",
    "DISALLOWED_UNICODE_CHARS_PATTERN = re.compile(r'[\\W_]+')\n",
    "DUPLICATE_DASH_PATTERN = re.compile(r'-{2,}')\n",
    "NUMBERS_PATTERN = re.compile(r'(?<=\\d),(?=\\d)')\n",
    "DEFAULT_SEPARATOR = '-'\n",
    "\n",
    "\n",
    "def slugify(text, entities=True, decimal=True, hexadecimal=True, max_length=0, word_boundary=False,\n",
    "            separator=DEFAULT_SEPARATOR, save_order=False, stopwords=(), regex_pattern=None, lowercase=True,\n",
    "            replacements=(), allow_unicode=False):\n",
    "    \"\"\"\n",
    "    Make a slug from the given text.\n",
    "    :param text (str): initial text\n",
    "    :param entities (bool): converts html entities to unicode\n",
    "    :param decimal (bool): converts html decimal to unicode\n",
    "    :param hexadecimal (bool): converts html hexadecimal to unicode\n",
    "    :param max_length (int): output string length\n",
    "    :param word_boundary (bool): truncates to complete word even if length ends up shorter than max_length\n",
    "    :param save_order (bool): if parameter is True and max_length > 0 return whole words in the initial order\n",
    "    :param separator (str): separator between words\n",
    "    :param stopwords (iterable): words to discount\n",
    "    :param regex_pattern (str): regex pattern for disallowed characters\n",
    "    :param lowercase (bool): activate case sensitivity by setting it to False\n",
    "    :param replacements (iterable): list of replacement rules e.g. [['|', 'or'], ['%', 'percent']]\n",
    "    :param allow_unicode (bool): allow unicode characters\n",
    "    :return (str):\n",
    "    \"\"\"\n",
    "\n",
    "    # user-specific replacements\n",
    "    if replacements:\n",
    "        for old, new in replacements:\n",
    "            text = text.replace(old, new)\n",
    "\n",
    "    # ensure text is unicode\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text, 'utf-8', 'ignore')\n",
    "\n",
    "    # replace quotes with dashes - pre-process\n",
    "    text = QUOTE_PATTERN.sub(DEFAULT_SEPARATOR, text)\n",
    "\n",
    "    # decode unicode\n",
    "    if not allow_unicode:\n",
    "        text = unidecode.unidecode(text)\n",
    "\n",
    "    # ensure text is still in unicode\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text, 'utf-8', 'ignore')\n",
    "\n",
    "    # character entity reference\n",
    "    if entities:\n",
    "        text = CHAR_ENTITY_PATTERN.sub(lambda m: chr(name2codepoint[m.group(1)]), text)\n",
    "\n",
    "    # decimal character reference\n",
    "    if decimal:\n",
    "        try:\n",
    "            text = DECIMAL_PATTERN.sub(lambda m: chr(int(m.group(1))), text)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # hexadecimal character reference\n",
    "    if hexadecimal:\n",
    "        try:\n",
    "            text = HEX_PATTERN.sub(lambda m: chr(int(m.group(1), 16)), text)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # translate\n",
    "    if allow_unicode:\n",
    "        text = unicodedata.normalize('NFKC', text)\n",
    "    else:\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    if sys.version_info < (3,):\n",
    "        text = text.encode('ascii', 'ignore')\n",
    "\n",
    "    # make the text lowercase (optional)\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    # remove generated quotes -- post-process\n",
    "    text = QUOTE_PATTERN.sub('', text)\n",
    "\n",
    "    # cleanup numbers\n",
    "    text = NUMBERS_PATTERN.sub('', text)\n",
    "\n",
    "    # replace all other unwanted characters\n",
    "    if allow_unicode:\n",
    "        pattern = regex_pattern or DISALLOWED_UNICODE_CHARS_PATTERN\n",
    "    else:\n",
    "        pattern = regex_pattern or DISALLOWED_CHARS_PATTERN\n",
    "\n",
    "    text = re.sub(pattern, DEFAULT_SEPARATOR, text)\n",
    "\n",
    "    # remove redundant\n",
    "    text = DUPLICATE_DASH_PATTERN.sub(DEFAULT_SEPARATOR, text).strip(DEFAULT_SEPARATOR)\n",
    "\n",
    "    # remove stopwords\n",
    "    if stopwords:\n",
    "        if lowercase:\n",
    "            stopwords_lower = [s.lower() for s in stopwords]\n",
    "            words = [w for w in text.split(DEFAULT_SEPARATOR) if w not in stopwords_lower]\n",
    "        else:\n",
    "            words = [w for w in text.split(DEFAULT_SEPARATOR) if w not in stopwords]\n",
    "        text = DEFAULT_SEPARATOR.join(words)\n",
    "\n",
    "    # finalize user-specific replacements\n",
    "    if replacements:\n",
    "        for old, new in replacements:\n",
    "            text = text.replace(old, new)\n",
    "\n",
    "    # smart truncate if requested\n",
    "    if max_length > 0:\n",
    "        text = smart_truncate(text, max_length, word_boundary, DEFAULT_SEPARATOR, save_order)\n",
    "\n",
    "    if separator != DEFAULT_SEPARATOR:\n",
    "        text = text.replace(DEFAULT_SEPARATOR, separator)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating song ids for valid file naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_data_proper_name.csv\", index_col = 0)\n",
    "df = df.reset_index()\n",
    "\n",
    "df['id'] = list(map(lambda x: slugify(x, lowercase=False, separator='_',) , df['id'].values))\n",
    "df.to_csv(\"df_data_proper_name.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding missing uri's and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access token needs an update every hour\n",
    "access = \"Bearer \"\n",
    "\n",
    "def find_uri(artist, track):\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': access,}\n",
    "\n",
    "    params = {\n",
    "        'q': \"Artist : \" + artist + \" Track: \" + track,\n",
    "        'type': 'track',\n",
    "        'limit': '1',\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.spotify.com/v1/search', params=params, headers=headers)\n",
    "    return response.json()['tracks']['items'][0]['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(uri):\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': access,}\n",
    "\n",
    "    params = {\n",
    "        'ids': uri.split(\":\")[-1]\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.spotify.com/v1/audio-features', params=params, headers=headers)\n",
    "    return response.json()['audio_features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if row['_uri'] == \"Unknown\":\n",
    "        uri = find_uri(row[\"_artist\"], row[\"_song\"])\n",
    "        df.at[i, '_uri'] = uri\n",
    "        \n",
    "        features = get_features(uri)\n",
    "        df.at[i, '_track'] = df.at[i, '_song']\n",
    "        df.at[i, '_danceability'] = features['danceability']\n",
    "        df.at[i, '_energy'] = features['energy']\n",
    "        df.at[i, '_key'] = features['key']      \n",
    "        df.at[i, '_loudness'] = features['loudness']   \n",
    "        df.at[i, '_mode'] = features['mode']\n",
    "        df.at[i, '_speechiness'] = features['speechiness']\n",
    "        df.at[i, '_acousticness'] = features['acousticness']        \n",
    "        df.at[i, '_instrumentalness'] = features['instrumentalness']   \n",
    "        df.at[i, '_liveness'] = features['liveness']      \n",
    "        df.at[i, '_valence'] = features['valence']\n",
    "        df.at[i, '_tempo'] = features['tempo']\n",
    "        df.at[i, '_duration_ms'] = features['duration_ms']\n",
    "        df.at[i, '_time_signature'] = features['time_signature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    r = list(row)\n",
    "    if r[7] != 'Unknown':   # r[7] = spotify song uri \n",
    "        try: \n",
    "            spotify_cover_downloader(r[7], CLIENT_ID, CLIENT_SECRET, r[-2])  # r[-2] = song id\n",
    "        except SystemExit:\n",
    "            os.system(\"ffplay.exe \" + 'beep.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
